{

\setlength{\parindent}{0pt}
\setlength{\parskip}{1em}

\chapter{Evaluation}
\label{chapter:evaluation}

An implemented flexible pipeline gives the opportunity to conveniently train, convert and deploy various different model configurations for \gls{devboard}.
It enables fast switching between model's architecture, training and deployment configurations, for instance:
utilizing different number of input channels, changing the spatial resolution of input tensor, utilizing different training, validation, and testing subsets.
Tailoring these configurations to user needs requires only minor changes to pipeline code.

During the development process, numerous model architectures were designed and trained. Most of them served as prototypes for the debugging process.
For instance, the model \code{simple} yielded the first inference results, that are presented in \secshortref{sec:deployment}.
After successful implementation phase, five models were selected for the evaluation process. These models were trained for an appropriate number of epochs,
their inference time performance was checked on \gls{devboard} and evaluation metrics gathered utilizing evaluation pipeline. 
One of these model was the first to yield qualitatively high results.
It hosts a simplified and adjusted for edge inference \code{Cloud-Net} architecture\cite{CloudNet2019}.
The first model's architecture will be called \code{earlyCloudEdgeQ} in the scope of this work.
The remaining four models are all of the exact same architecture, which is an improved version of \code{earlyCloudEdgeQ}.
Architecture of these models is therefore called \code{improvedCloudEdgeQ}.
But these models are utilizing different number of input channels (\gls{rgb} with \gls{nir} or only \gls{rgb}),
and they furthermore are using different input patch size (either \ensuremath{192\times192} or \ensuremath{384\times384}).
It has to be mentioned, that all five of these models follow classical \code{uNet} structure,
outlined in \secshortref{subsec:stateoftheart}. They contain encoder, bottleneck and decoder,
as well as the skip-connections between corresponding encoder and decoder blocks.


Below the detailed description of both architectures is presented:
\begin{itemize}
    \item \textbf{earlyCloudEdgeQ}: The model hosts three encoder blocks, a bottleneck block, and three decoder blocks.
    Each encoder block consists of two \code{Conv2D} layers and one \code{MaxPooling2D} layer,
    connected sequentionally one after another. Bottleneck consists of two sequentionally connected \code{Conv2D} layers.
    Each decoder block is represented by \code{Conv2DTranspose} layer, \code{Concatenate} layer, and two \code{Conv2D} layers,
    connected sequentionally. An output layer is represented by a \code{Conv2D} layer.
    Base number of filter is specified as 32 and is doubled/halved in each encoder/decoder block respectively, resulting in 256 filters in the bottleneck.
    \gls{bn} is applied accordingly after each \code{Conv2D} layer, but before its activation function. \gls{bn} is not applied in output layer.
    All suitable \glspl{tfop} are \gls{qat} annotaded. \gls{bce} is used as loss function and \code{adam} \cite{adam} is used as optimizer.
    \item \textbf{improvedCloudEdgeQ}: This model mimics the previous architecture with the following improvements.
    Between input and first encoder block a \code{Conv2D} layer with 16 filters is added to improve feature representation at the input stage,
    enabling the encoder to capture more consistent low-level patterns before deeper processing.
    Furthermore the model hosts now four encoder blocks, a bottleneck block, and four decoder blocks. The bottleneck design was adapted from \code{Cloud-Net},
    where a residual connection with a $1\times1$ projection ensures feature dimension alignment and efficient gradient flow. Additionally,
    the integration of dropout regularization reduces overfitting, resulting in a more robust and generalizable feature representation at the network's deepest layer.
    These ideas are copied from \code{Cloud-Net} architecture.
    To meet the limited \gls{edgetpu} \gls{sram} capacity, the decoder blocks were simplified by removing one \code{Conv2D} layer from each block,
    except for the final decoder block before the output layer, which retains two \code{Conv2D} layers to preserve finer spatial resolution.
    Additionally, using \gls{bce} combined with \ensuremath{0.5 \cdot DiceLoss} as the loss function balances pixel-wise accuracy with overlap-based region matching,
    leading to better segmentation performance than plain \gls{bce} \cite{bcedice1, bcedice2}.

\end{itemize}

\code{improvedCloudEdgeQ} architecture can be summarized as an adjusted \code{Cloud-Net} model to meet the contraints of embedded \gls{edgetpu} development.
Necessary simplifications were made. Both \code{earlyCloudEdgeQ} and \code{improvedCloudEdgeQ} architectures can be investigated more detailed in the
\code{model.py} file,
as well as compared with \code{Cloud-Net} model
architecture\footnote{\url{https://github.com/SorourMo/Cloud-Net-A-semantic-segmentation-CNN-for-cloud-detection/blob/master/Cloud-Net/cloud_net_model.py}}.

Following table further specifies the differencec between the models, providing information about number of input channels (CH),
size of an input patch (In size), number of training epochs (Epochs), estimated count of arithmetic operations in billions (Ops (B)),
On-chip/Off-chip memory used for caching model parameters (On-chip (MB)/Off-chip (KB)),
inference time needed by \gls{devboard} to process one batch in milliseconds (Inf. Time (ms)).

\begin{table}[h!]
\centering
\caption{Comparison of model properties and deployment metrics}
\label{tab:model_comparison}
\renewcommand{\arraystretch}{1.3}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|c|c|c|c|c|c|c|}
\hline
\textbf{Model} & \textbf{CH} & \textbf{In size} & \textbf{Epochs} & \textbf{Ops (B)} & \textbf{On-chip (MB)} & \textbf{Off-chip (KB)} & \textbf{Inf. Time (ms)} \\ \hline
early      & 4 & 192 & 100  & 10.4 & 1.9 & 46  & 15.2 \\ \hline
improved~1 & 3 & 192 & 54   & 11.6 & 5.7 & 342 & 20.5 \\ \hline
improved~2 & 3 & 384 & 46   & 46.3 & 6.0 & 349 & 12.7 \\ \hline
improved~3 & 4 & 192 & 51   & 11.6 & 5.7 & 342 & 10.3 \\ \hline
improved~4 & 4 & 384 & 45   & 46.4 & 6.0 & 349 & 25.8 \\ \hline
\end{tabular}%
}
\end{table}

\todo{inference time coral and add learnable params!}

Models were evaluated on a test set, containing 20 scenes. The evaluation metrics, outlined in \secshortref{subsec:evalmetrics}
were calculated per scene and then averaged:
IoU, Dice Coefficient, Precision, Recall, Accuracy. Averaging does not skew the results, because all scene are of approximately the same size.
Furthermore, for each model except \code{early} the best binarization threshold was calculated immediately after the training precess,
utilizing the bestF1 score, obtained on a validation set.
This improves model to be inference-ready with its own calibrated best threshold for immediate binarization of predicted masks.
For \code{early} model no threshold was calculated, since to the point of its training, the feature was not yet implemented.
Features for the reproducibility of shuffling the datasets were not implemented at the time too,
leaving no chance to perform \code{PRC} evaluation on the same validation set to make up for the best validation threshold.
In addition to determining the optimal threshold from the validation set,
a per-scene threshold was computed individually for each of the 20 test scenes and subsequently averaged.
This procedure is even more optimistic than selecting a single global test threshold,
since it implicitly adapts to each test scene and therefore overestimates true generalization performance.
Nonetheless, presenting these results is useful, as it illustrates the upper bound of performance
achievable under ideal threshold tuning and underscores the strong influence of threshold choice on segmentation quality.
The final evaluation results are represented on three column chart below,
whereas second and third charts are derived from the first one, splitting between validation set threshold and test set threshold
for better visual comparison possibility.
\code{improvedCloudEdgeQ} models are represented only by their parameters configuration, such as number of input channels and input patch' size,
\code{earlyCloudEdgeQ} is highlighted additionally as \code{early} model. 

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{files/evalRes.pdf}
  \caption{The basic workflow to create a model for the Edge TPU}
  \label{fig:evalres}
\end{figure}

\begin{figure}[H]
  \centering
  \begin{subfigure}[t]{\textwidth}
    \centering
    \includegraphics[width=\textwidth,height=0.45\textheight,keepaspectratio]{files/valSetThr.pdf}
    \caption{Links}
  \end{subfigure}
  \vspace{0.8em}
  \begin{subfigure}[t]{\textwidth}
    \centering
    \includegraphics[width=\textwidth,height=0.45\textheight,keepaspectratio]{files/testSetThr.pdf}
    \caption{Rechts}
  \end{subfigure}
  \caption{Zwei Diagramme Ã¼bereinander (als PDF).}
\end{figure}

By analizing these results, following key insights can be made:
\begin{itemize}
    \item A general upward performance trend can clearly be seen with increasing input patch resolution and with addition of \gls{nir} channel.
    This is expected, as the model benifits from additional input information sources.
    \item \code{improvedCloudEdgeQ} architecture performs generally better than \code{earlyCloudEdgeQ} given the architecture improvements.
    \item At input size \ensuremath{192\times192}, adding the \gls{nir} channel did not improve recall and in fact led to a slight reduction,
    when analizing the validation threshold. This effect likely arises because the additional spectral information increases input dimensionality without
    providing sufficient spatial context at the lower resolution. As a result, the model becomes more conservative at cloud boundaries and thin structures,
    which reduces false positives but slightly increases the number of missed cloud pixels, leading to lower recall.
    \item The accuracy metric is constanltly at a very high level, but it has better not to be qualified as a reliable metric in the
    cloud segmentation case, as explained in \secshortref{subsec:evalmetrics}. <TODO EXPLAIN THERE>
\end{itemize}

Based on the evaluation metrics and taking the inference time on \gls{devboard} into consideration the \code{improvedCloudEdgeQ} model,
with \gls{rgb} and \code{nir} input channels as well as \ensuremath{192\times192} spatial resolution, is proposed as the best suitable model
out of all trained and evaluated models in the scope of this work. This model represents the golden middle between edge device inference speed
and performance metrics.
However, if the input data lacks \code{nir} channel, providing only \code{rgb} imagery, the best model is chosen to be
\code{improvedCloudEdgeQ} of \ensuremath{384\times384}, trading significantly increased inference time for the more than acceptable performance.

}